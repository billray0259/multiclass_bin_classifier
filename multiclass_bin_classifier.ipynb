{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras import layers\n",
    "from keras import Model\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_binary_mlp(hidden_sizes, n_out, activation=\"leaky_relu\"):\n",
    "    input_tensor = layers.Input(shape=(28*28,))\n",
    "    z = input_tensor\n",
    "    for size in hidden_sizes:\n",
    "        z = layers.Dense(size, activation=activation)(z)\n",
    "    z = layers.Dense(n_out, activation=\"tanh\")(z)\n",
    "    model = Model(input_tensor, z)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Custom loss function\n",
    "# minimize the magnitude of the covariance over the predictions\n",
    "def multiclass_loss(cov_weight=1, center_weight=1, mag_weight=1):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Calculate the covariance matrix\n",
    "        # https://stackoverflow.com/questions/47709854/how-to-get-covariance-matrix-in-tensorflow\n",
    "        x = y_pred\n",
    "        mean_x = K.mean(x, axis=0, keepdims=True)\n",
    "        mx = K.transpose(mean_x) @ mean_x\n",
    "        vx = (K.transpose(x) @ x)/K.cast(K.shape(x)[0], dtype=\"float32\")\n",
    "        cov_xx = vx - mx\n",
    "        # set the diagonal to zero\n",
    "        cov_xx = tf.linalg.set_diag(cov_xx, tf.zeros_like(tf.linalg.diag_part(cov_xx)))\n",
    "\n",
    "        cov_loss = K.mean(K.abs(cov_xx)) # Optimal at 0\n",
    "\n",
    "        # Calculate the magnitude of the average prediction\n",
    "        center_loss = K.abs(mean_x) # Optimal at 0\n",
    "\n",
    "        # Calculate the average magnitude of the predictions\n",
    "        mag_loss = K.mean(K.abs(x)) # Optimal at 1\n",
    "\n",
    "        # Calculate the loss\n",
    "        return cov_weight*cov_loss + center_weight*center_loss - mag_weight*mag_loss + mag_weight\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    def __init__(self, X, y, hidden_sizes, n_out, activation=\"relu\", n_classes=10, cov_weight=1, center_weight=1, mag_weight=1, seed=None):\n",
    "        self.model = multi_binary_mlp(hidden_sizes=hidden_sizes, n_out=n_out, activation=activation)\n",
    "        loss_fn = multiclass_loss(cov_weight=cov_weight, center_weight=center_weight, mag_weight=mag_weight)\n",
    "        self.model.compile(optimizer=\"adam\", loss=loss_fn)\n",
    "\n",
    "        self.n_out = n_out\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.buckets = None\n",
    "        self.n_classes = n_classes\n",
    "    \n",
    "    \n",
    "    def train_nn(self, epochs=10, batch_size=128):\n",
    "        self.model.fit(self.X, self.y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def get_outputs(self, X):\n",
    "        return self.model.predict(X) # (batch_size, n_out)\n",
    "\n",
    "    def outputs_to_index(self, outputs):\n",
    "        bin_outputs = (outputs > 0).astype(int) # (batch_size, n_out)\n",
    "\n",
    "        # interpret bin_outputs as a batch of binary numbers\n",
    "        # convert each binary number to a decimal number\n",
    "        two_powers = 2**np.arange(outputs.shape[1]) # (1, n_out)\n",
    "        indecies = bin_outputs.dot(two_powers) # (batch_size,)\n",
    "        return indecies\n",
    "\n",
    "\n",
    "    def train_buckets(self):\n",
    "        outputs = self.get_outputs(self.X) # (batch_size, n_out)\n",
    "        indecies = self.outputs_to_index(outputs)\n",
    "        n_buckets = 2**self.n_out\n",
    "        self.buckets = np.zeros((n_buckets, self.n_classes)) # (n_buckets, n_classes)\n",
    "        for i, index in enumerate(indecies):\n",
    "            self.buckets[index, self.y[i]] += 1\n",
    "        \n",
    "        # normalize each row\n",
    "        self.buckets = self.buckets / (self.buckets.sum(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.buckets is None:\n",
    "            # raise an error\n",
    "            raise Exception(\"You must train the buckets before you can predict: classifier.train_buckets()\")\n",
    "        \n",
    "        outputs = self.get_outputs(X) # (batch_size, n_out)\n",
    "        indecies = self.outputs_to_index(outputs)\n",
    "        return self.buckets[indecies]\n",
    "    \n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred = y_pred.argmax(axis=1)\n",
    "        return np.mean(y_pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# flatten 28x28 images to a 784 vector for each image\n",
    "x_train = x_train.reshape((60000, 28*28))\n",
    "x_test = x_test.reshape((10000, 28*28))\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 4\n",
    "classifier = Classifier(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    hidden_sizes=[128, 64],\n",
    "    n_out=n_out,\n",
    "    cov_weight=0.2,\n",
    "    center_weight=1,\n",
    "    mag_weight=0.2,\n",
    ")\n",
    "classifier.train_buckets()\n",
    "starting_buckets = classifier.buckets.copy()\n",
    "print(\"Untrained Accuracy:\", classifier.evaluate(x_test, y_test))\n",
    "classifier.train_nn(epochs=10)\n",
    "classifier.train_buckets()\n",
    "ending_buckets = classifier.buckets.copy()\n",
    "print(\"Trained Accuracy:\", classifier.evaluate(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the difference between the starting and ending buckets\n",
    "import matplotlib.pyplot as plt\n",
    "# plot the two images next to each other with the same colorbar\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, n_out*2))\n",
    "ax[0].imshow(starting_buckets)\n",
    "ax[1].imshow(ending_buckets)\n",
    "# label the axes\n",
    "ax[0].set_xlabel(\"Class\")\n",
    "ax[1].set_xlabel(\"Class\")\n",
    "ax[0].set_ylabel(\"Bucket Index\")\n",
    "ax[1].set_ylabel(\"Bucket Index\")\n",
    "\n",
    "# Title the images\n",
    "ax[0].set_title(\"Starting Buckets\")\n",
    "ax[1].set_title(\"Ending Buckets\")\n",
    "\n",
    "# set tick space to be every number\n",
    "ax[0].set_xticks(np.arange(10))\n",
    "ax[1].set_xticks(np.arange(10))\n",
    "ax[0].set_yticks(np.arange(2**n_out))\n",
    "ax[1].set_yticks(np.arange(2**n_out))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = classifier.get_outputs(x_test)\n",
    "# for each output plot a histogram of the values\n",
    "fig, ax = plt.subplots(n_out, 1, figsize=(8, 14))\n",
    "for i in range(n_out):\n",
    "    ax[i].hist(outputs[:, i])\n",
    "    ax[i].set_xlabel(\"Output {}\".format(i))\n",
    "    ax[i].set_ylabel(\"Node %d\" % 2**i)\n",
    "    # remove ticks\n",
    "    # ax[i].set_yticks([])\n",
    "    # ax[i].set_xticks([-1, 1])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
